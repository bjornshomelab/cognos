#!/usr/bin/env python3
"""
divergence_semantics.py â€” Externe metacognitive conflict resolution.

When CognOS detects SYNTHESIZE (perspective conflict), this module
extracts the underlying assumptions that drive the divergence.

Core idea: perspektiv A och B Ã¤r kohÃ¤renta, men bygger pÃ¥ olika antaganden.
Systemet mÃ¥ste kunna sÃ¤ga VILKA antaganden som skiljer dem.

Det Ã¤r meta-nivÃ¥ 1: frÃ¥n "vi Ã¤r oeniga" till "vi antar olika saker om X".

Tre funktioner:
  - synthesize_reason()   : extrahera underliggande antaganden frÃ¥n rÃ¶stfÃ¶rdelning
  - frame_transform()     : detektera om frÃ¥gan Ã¤r felstÃ¤lld (meta-nivÃ¥ 2)
  - convergence_check()   : stoppa nÃ¤r C och antaganden stabiliseras (meta-nivÃ¥ 3)
"""

import json
import sys
from pathlib import Path
from typing import Optional, Any

# Try to import Jasper's ask functions; fallback to direct API if unavailable
try:
    sys.path.append('/media/bjorn/iic/Jasper')
    from jasper_brain import ask_groq, ask_github_models
except ImportError:
    ask_groq = None
    ask_github_models = None


def _call_llm(system: str, prompt: str) -> Optional[str]:
    """Try GitHub Models first, then Groq, then return None."""
    if ask_github_models:
        try:
            result = ask_github_models(system, prompt)
            if result:
                return result
        except Exception:
            pass
    if ask_groq:
        try:
            result = ask_groq(system, prompt)
            if result:
                return result
        except Exception:
            pass
    return None


def _fallback_synthesize_reason(question: str, majority_choice: str, minority_choice: str, 
                                majority_alt: str, minority_alt: str, confidence: float) -> dict:
    """Graceful fallback when LLM is unavailable."""
    return {
        'question': question,
        'majority_choice': majority_choice,
        'minority_choice': minority_choice,
        'majority_assumption': f'Majoriteten ({majority_choice}) fÃ¶redrar: {majority_alt}',
        'minority_assumption': f'Minoriteten ({minority_choice}) fÃ¶redrar: {minority_alt}',
        'divergence_source': 'OkÃ¤nd â€” LLM ej tillgÃ¤nglig',
        'divergence_type': 'unknown',
        'divergence_axes': [],
        'integration_strategy': 'Kunde inte analysera (LLM ej tillgÃ¤nglig)',
        'integration_mode': 'clarification',
        'meta_question': 'Kunde inte generera metafrÃ¥ga',
        'meta_alternatives': [],
        'confidence': confidence,
        'is_resolvable': False,
    }


def synthesize_reason(
    question: str,
    alternatives: list[str],
    vote_distribution: dict,
    confidence: float,
    is_multimodal: bool,
    context: Optional[str] = None,
    llm_fn: Optional[Any] = None,
) -> dict:
    """
    Extrahera underliggande antaganden frÃ¥n en divergent rÃ¶stfÃ¶rdelning.

    Input:
      question: UrsprungsfrÃ¥gan (t.ex. "Ã„r hypotesen falsifierbar?")
      alternatives: SvarsmÃ¶jligheter (t.ex. ["A: Svag", "B: Medel", "C: Stark"])
      vote_distribution: RÃ¶ster per svar (t.ex. {"B": 3, "C": 2})
      confidence: CognOS confidence score
      is_multimodal: Om Ue-distributionen Ã¤r bimodal
      context: Valfri kontextinformation

    Output:
      {
        'question': str,
        'majority_choice': str,
        'majority_assumption': str,        # Vad majoriteten antar
        'minority_choice': str,
        'minority_assumption': str,        # Vad minoriteten antar
        'divergence_source': str,          # VAR skiljer sig antagandena?
        'integration_strategy': str,       # Hur kombinerar man dem?
        'meta_question': str,              # Vad behÃ¶ver vi klargÃ¶ra?
        'confidence': float,
        'is_resolvable': bool,             # Kan divergensen lÃ¶sas genom mer info?
      }
    """

    # Identifiera majoritet och minoritet
    if not vote_distribution or confidence >= 0.95:
        return {
            'question': question,
            'majority_choice': None,
            'majority_assumption': 'Konsensus â€” ingen divergens att analysera.',
            'minority_choice': None,
            'minority_assumption': None,
            'divergence_source': None,
            'integration_strategy': 'Ingen syntes behÃ¶vlig.',
            'meta_question': None,
            'confidence': confidence,
            'is_resolvable': True,
        }

    sorted_votes = sorted(vote_distribution.items(), key=lambda x: x[1], reverse=True)
    majority_choice, majority_count = sorted_votes[0]
    minority_choice, minority_count = sorted_votes[1] if len(sorted_votes) > 1 else (None, 0)

    # Mappa choicelabels till alternativstext
    choice_to_alt = {}
    for i, alt in enumerate(alternatives):
        label = chr(65 + i)  # A, B, C, ...
        choice_to_alt[label] = alt

    majority_alt = choice_to_alt.get(majority_choice, f"Alternative {majority_choice}")
    minority_alt = choice_to_alt.get(minority_choice, f"Alternative {minority_choice}") if minority_choice else None

    # Skapa prompt fÃ¶r LLM att extrahera antaganden + strukturera divergensen
    prompt = f"""
Du Ã¤r en filosofisk analytiker som specialiserar sig pÃ¥ underliggande antaganden i diskoord.

FrÃ¥ga: {question}

Alternativ:
{chr(10).join(f"  {label}: {choice_to_alt.get(label, '?')}" for label in sorted(choice_to_alt.keys()))}

RÃ¶stfÃ¶rdelning:
  Majoritet ({majority_count} votes): {majority_choice} â€” {majority_alt}
  Minoritet ({minority_count} votes): {minority_choice} â€” {minority_alt}

Din uppgift:
1. Identifiera det OLIKA ANTAGANDET som driver divergensen.
2. Klassificera divergenstypen: epistemic (vad Ã¤r sant), normative (vad bÃ¶r gÃ¶ras), scope (vilket omrÃ¥de), eller cost_of_error (ej ett utan annat Ã¤r farligare)
3. FÃ¶reslÃ¥ integrationsstrategi: reframe (Ã¤ndra perspektiv), tradeoff (acceptera bÃ¥da), empirical_test (testa empiriskt), eller clarification (klargÃ¶r begrepp)
4. Generera 3 konkreta nÃ¤sta steg baserat pÃ¥ integration_mode

Svar i JSON-format (bara JSON, inget annat):
{{
  "majority_assumption": "Majoriteten antar att...",
  "minority_assumption": "Minoriteten antar att...",
  "divergence_source": "Divergensen kommer frÃ¥n antagandet om [X]",
  "divergence_type": "epistemic",
  "divergence_axes": [
    {{
      "dimension": "Namn pÃ¥ axel",
      "majority_position": 0.8,
      "minority_position": 0.2,
      "interpretation": "Vad denna axel betyder"
    }}
  ],
  "integration_strategy": "Konkret actionable strategi (inte bara narrativ)",
  "integration_mode": "clarification",
  "meta_question": "NÃ¤sta frÃ¥ga vi bÃ¶r stÃ¤lla",
  "meta_alternatives": [
    "Alternativ 1: konkret nÃ¤sta steg",
    "Alternativ 2: konkret nÃ¤sta steg",
    "Alternativ 3: konkret nÃ¤sta steg"
  ],
  "is_resolvable": true
}}
"""

    system = "Du Ã¤r en filosofisk analytiker. Svara ENBART med giltigt JSON, inget annat. Fokus: operativ struktur, inte bara narrativ."

    # Use injected llm_fn, fallback to _call_llm
    llm_to_use = llm_fn if llm_fn else _call_llm
    if not llm_to_use:
        # Emergency fallback if no LLM available at all
        return _fallback_synthesize_reason(question, majority_choice, minority_choice, majority_alt, minority_alt, confidence)
    
    response_text = llm_to_use(system, prompt)

    if not response_text:
        # Fallback om LLM inte tillgÃ¤nglig
        return _fallback_synthesize_reason(question, majority_choice, minority_choice, majority_alt, minority_alt, confidence)

    # Parsa JSON frÃ¥n response
    try:
        import re
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            data = json.loads(json_match.group())
        else:
            data = {}
    except (json.JSONDecodeError, ValueError):
        data = {}

    # Return rich structured output
    return {
        'question': question,
        'majority_choice': majority_choice,
        'minority_choice': minority_choice,
        'majority_assumption': data.get('majority_assumption', f'Majoriteten fÃ¶redrar {majority_choice}'),
        'minority_assumption': data.get('minority_assumption', f'Minoriteten fÃ¶redrar {minority_choice}'),
        'divergence_source': data.get('divergence_source', 'OkÃ¤nd'),
        'divergence_type': data.get('divergence_type', 'epistemic'),  # NEW: categorization
        'divergence_axes': data.get('divergence_axes', []),  # NEW: geometric structure
        'integration_strategy': data.get('integration_strategy', 'Kunde inte analysera'),
        'integration_mode': data.get('integration_mode', 'clarification'),  # NEW: categorization
        'meta_question': data.get('meta_question', 'Ingen metafrÃ¥ga genererad'),
        'meta_alternatives': data.get('meta_alternatives', []),  # NEW: dynamic alternatives
        'confidence': confidence,
        'is_resolvable': data.get('is_resolvable', True),
    }


def frame_transform(question: str, confidence: float = 0.0, llm_fn: Optional[Any] = None) -> dict:
    """
    Meta-nivÃ¥ 2: Detektera om frÃ¥gan sjÃ¤lv Ã¤r felstÃ¤lld.

    Returnerar:
      {
        'original_question': str,
        'is_well_framed': bool,
        'reframed_question': Optional[str],
        'problem_type': str,  # 'ill_posed' | 'ambiguous' | 'category_error' | 'ok'
        'recommendation': str,
      }
    """

    prompt = f"""
FrÃ¥ga: {question}

Ã„r denna frÃ¥ga vÃ¤lstÃ¤lld fÃ¶r att kunna fÃ¥ ett klart svar?

Kontrollera:
1. Ã„r termer tydligt definierade? (Eller Ã¤r det begreppsfÃ¶rvirring?)
2. Kan frÃ¥gan svaras objektivt? (Eller Ã¤r det vÃ¤rdeomdÃ¶me presenterat som faktum?)
3. Finns det dolt antagande i frÃ¥geformuleringen? (Eller Ã¤r den neutral?)

Om frÃ¥gan Ã¤r felstÃ¤lld, fÃ¶reslÃ¥ en OMFORMULERING.

Svar i JSON:
{{
  "is_well_framed": true/false,
  "problem_type": "ok" | "ill_posed" | "ambiguous" | "category_error",
  "reframed_question": "Omformulerad frÃ¥ga eller null",
  "reason": "FÃ¶rklaring kort och direkt"
}}
"""

    system = "Du Ã¤r logiker. Svara ENBART med giltigt JSON."

    # Use injected llm_fn, fallback to _call_llm
    llm_to_use = llm_fn if llm_fn else _call_llm
    response_text = llm_to_use(system, prompt)

    if not response_text:
        return {
            'original_question': question,
            'is_well_framed': True,
            'reframed_question': None,
            'problem_type': 'ok',
            'recommendation': 'Kunde inte analysera (LLM ej tillgÃ¤nglig)',
        }

    try:
        import re
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            data = json.loads(json_match.group())
        else:
            data = {}
    except (json.JSONDecodeError, ValueError):
        data = {}

    return {
        'original_question': question,
        'is_well_framed': data.get('is_well_framed', True),
        'reframed_question': data.get('reframed_question'),
        'problem_type': data.get('problem_type', 'ok'),
        'recommendation': data.get('reason', 'Ingen analys tillgÃ¤nglig'),
    }


def convergence_check(
    iteration: int,
    confidence_history: list[float],
    assumption_history: list[str],
    threshold: float = 0.05,
) -> dict:
    """
    Meta-nivÃ¥ 3: Stoppa rekursion nÃ¤r systemet konvergerat.

    Input:
      iteration: Aktuell iteration
      confidence_history: C-vÃ¤rden frÃ¥n tidigare iterationer
      assumption_history: Extraherade huvudantaganden frÃ¥n tidigare iterationer
      threshold: TillÃ¥ten fÃ¶rÃ¤ndring innan stabil

    Output:
      {
        'should_continue': bool,
        'reason': str,
        'stability_score': float,  # 0-1, dÃ¤r 1 = perfekt stabil
      }
    """

    if iteration < 2:
        return {
            'should_continue': True,
            'reason': 'FÃ¶r tidigt att dÃ¶ma konvergens (< 2 iterationer)',
            'stability_score': 0.0,
        }

    # Kontrollera C-stabilitet
    recent_c = confidence_history[-2:]
    if len(recent_c) == 2:
        c_change = abs(recent_c[1] - recent_c[0])
        c_stable = c_change < threshold
    else:
        c_stable = False

    # Kontrollera antagandestabilitet
    recent_assumptions = assumption_history[-2:] if len(assumption_history) >= 2 else []
    if len(recent_assumptions) == 2:
        assumptions_same = recent_assumptions[0] == recent_assumptions[1]
    else:
        assumptions_same = False

    stability_score = (float(c_stable) + float(assumptions_same)) / 2.0

    should_continue = not (c_stable and assumptions_same)

    reason = ""
    if c_stable:
        reason += "âœ“ Confidence stabil. "
    else:
        reason += f"âœ— Confidence varierar (Î”={c_change:.3f}). "

    if assumptions_same:
        reason += "âœ“ Antaganden stabila."
    else:
        reason += "âœ— Antaganden har fÃ¶rÃ¤ndrats."

    return {
        'should_continue': should_continue,
        'reason': reason,
        'stability_score': stability_score,
    }


if __name__ == '__main__':
    # Demo pÃ¥ en enkelt divergens
    print("=" * 80)
    print("DIVERGENCE SEMANTICS â€” DEMO")
    print("=" * 80)

    result = synthesize_reason(
        question="Ã„r hypotesen falsifierbar?",
        alternatives=[
            "A: Svag falsifierbarhet",
            "B: Delvis falsifierbar men krÃ¤ver striktare mÃ¤ttrÃ¶sklar",
            "C: Starkt falsifierbar med tydliga kriterier"
        ],
        vote_distribution={"B": 3, "C": 2},
        confidence=0.309,
        is_multimodal=False,
    )

    print("\nğŸ“Š RESULTAT")
    print(f"FrÃ¥ga: {result['question']}")
    print(f"Majoritet: {result['majority_choice']} ({result['majority_assumption'][:60]}...)")
    print(f"Minoritet: {result['minority_choice']} ({result['minority_assumption'][:60]}...)")
    print(f"\nğŸ” Divergence Source: {result['divergence_source'][:100]}...")
    print(f"ğŸ¤ Integration: {result['integration_strategy'][:100]}...")
    print(f"â“ Meta-question: {result['meta_question'][:100]}...")
    print(f"ğŸ’ª Resolvable: {result['is_resolvable']}")
    print(f"ğŸ“ˆ Confidence: {result['confidence']:.3f}")

    print("\n" + "=" * 80)
